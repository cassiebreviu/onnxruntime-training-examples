{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Accelerate finetuning of GPT2 model for Language Modeling task using ONNX Runtime Training\r\n",
        "This notebook contains a walkthrough of using ONNX Runtime Training in Azure Machine Learning service to finetune [GPT2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) models. This example uses ONNX Runtime Training to fine-tune the GPT2 PyTorch model maintained at https://github.com/huggingface/transformers.\r\n",
        "Specificaly, we showcase finetuning the [pretrained GPT2-medium](https://huggingface.co/transformers/pretrained_models.html), which has 345M parameters using ORT.\r\n",
        "\r\n",
        "Steps:\r\n",
        "- Intialize an AzureML workspace\r\n",
        "- Register a datastore to use preprocessed data for training\r\n",
        "- Create an AzureML experiment\r\n",
        "- Provision a compute target\r\n",
        "- Create a PyTorch Estimator\r\n",
        "- Configure and Run\r\n",
        "\r\n",
        "Prerequisites\r\n",
        "If you are using an Azure Machine Learning [Compute Instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance) you are all set. Otherwise, you need to setup your environment by installing AzureML Python SDK to run this notebook. Refer to [How to use Estimator in Azure ML](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/how-to-use-estimator/how-to-use-estimator.ipynb) notebook first if you haven't already to establish your connection to the AzureML Workspace. \r\n",
        "\r\n",
        "Refer to instructions at https://github.com/microsoft/onnxruntime-training-examples/blob/master/huggingface-gpt2/README.md before running the steps below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check SDK installation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "source": [
        "import os\r\n",
        "import requests\r\n",
        "import sys\r\n",
        "import re\r\n",
        "\r\n",
        "# AzureML libraries\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Experiment, Workspace, Datastore, Run\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.container_registry import ContainerRegistry\r\n",
        "from azureml.core.runconfig import MpiConfiguration, RunConfiguration, DEFAULT_GPU_IMAGE\r\n",
        "from azureml.train.dnn import PyTorch\r\n",
        "from azureml.train.estimator import Estimator\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "from azure.common.client_factory import get_client_from_cli_profile\r\n",
        "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.34.0\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632252323904
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AzureML Workspace setup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "source": [
        "# Create or retrieve Azure machine learning workspace\r\n",
        "# see https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py\r\n",
        "ws = Workspace.get(name=\"demo\", subscription_id='', resource_group='demo')\r\n",
        "\r\n",
        "# Print workspace attributes\r\n",
        "print('Workspace name: ' + ws.name, \r\n",
        "      'Workspace region: ' + ws.location, \r\n",
        "      'Subscription id: ' + ws.subscription_id, \r\n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: demo\n",
            "Workspace region: westus2\n",
            "Subscription id: 47c81f7b-f720-4f17-9116-69d540091679\n",
            "Resource group: demo\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632252328240
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register Datastore\r\n",
        "Before running the step below, data prepared using the instructions at https://github.com/microsoft/onnxruntime-training-examples/blob/master/huggingface-gpt2/README.md should be transferred to an Azure Blob container referenced in the `Datastore` registration step. Refer to the documentation at https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data for details on using data in Azure ML experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "source": [
        "# Create a datastore from blob storage containing training data.\r\n",
        "# Consult README.md for instructions downloading and uploading training data.\r\n",
        "#ds = Datastore.register_azure_blob_container(workspace=ws, \r\n",
        "#                                             datastore_name='wikitext',\r\n",
        "#                                             account_name='demo1879244313', \r\n",
        "#                                             account_key='',\r\n",
        "#                                             container_name='tokenfiles')"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632252330674
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "source": [
        "ds = Datastore.get(workspace=ws, datastore_name='gpt_wikitext')\r\n",
        "# Print datastore attributes\r\n",
        "print('Datastore name: ' + ds.name, \r\n",
        "      'Container name: ' + ds.container_name, \r\n",
        "      'Datastore type: ' + ds.datastore_type, \r\n",
        "      'Workspace name: ' + ds.workspace.name, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datastore name: gpt_wikitext\n",
            "Container name: wikitext\n",
            "Datastore type: AzureBlob\n",
            "Workspace name: demo\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632260984749
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "train_data = Dataset.get_by_name(name='wikitext_train', workspace=ws)\r\n",
        "valid_data = Dataset.get_by_name(name='wikitext_valid', workspace=ws)\r\n",
        "\r\n",
        "print(train_data.name)\r\n",
        "print(valid_data.name)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wikitext_train\n",
            "wikitext_valid\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632252336449
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create AzureML Compute Cluster\n",
        "This recipe is supported on Azure Machine Learning Service using 16 x Standard_NC24rs_v3 or 8 x Standard_ND40rs_v2 VMs. In the next step, you will create an AzureML Compute cluster of Standard_NC40s_v2 GPU VMs with the specified name, if it doesn't already exist in your workspace. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "source": [
        "# Create GPU cluster\r\n",
        "#gpu_cluster_name = \"ortgptfinetune\" \r\n",
        "gpu_cluster_name = \"cassieb1\" \r\n",
        "try:\r\n",
        "    gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\r\n",
        "    print('Found existing compute target.')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_ND40rs_v2', min_nodes=0, max_nodes=8)\r\n",
        "    gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\r\n",
        "    gpu_compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632252338371
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Estimator\n",
        "Notes before running the following step:\n",
        "* Update the following step to replace two occurences of `<blob-path-to-training-data>` with the actual path in the datastore to the training data.\n",
        "* If you followed instructions at https://github.com/microsoft/onnxruntime-training-examples/blob/master/huggingface-gpt2/README.md to prepare data, make sure that the data and others files that are not code or config are moved out `workspace` directory. Data files should have been moved to a `Datastore` to use in training. \n",
        "* Update the occurance of `<tagged-onnxruntime-gpt-container>` with the tag of the built docker image pushed to a container registry. Similarly, update the `<azure-subscription-id>` and `<container-registry-resource-group>` with the contair registry's subscription ID and resource group.\n",
        "\n",
        "\n",
        "| VM SKU             | GPU memory   | gpu_count |    ORT_batch_size    |\n",
        "| ------------------ |:----------------:|:---------:|:-------:|\n",
        "| Standard_ND40rs_v2 | 32 GB            | 8         | 4   |\n",
        "| Standard_NC24rs_v3 | 16 GB            | 4         | 1   |\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "source": [
        "# this directory should contain run_language_modeling.py, after files copied over based on the instructions at https://github.com/microsoft/onnxruntime-training-examples/blob/master/huggingface-gpt2/README.md \r\n",
        "#project_folder = 'orttrainer/huggingface-gpt2/transformers/examples'\r\n",
        "project_folder = '.'\r\n",
        "\r\n",
        "# set MPI configuration\r\n",
        "# set processes per node to be equal to GPU count on SKU.\r\n",
        "# this will change based on NC v/s ND series VMs\r\n",
        "mpi_distr_config = MpiConfiguration(process_count_per_node=4, node_count=1)\r\n",
        "\r\n",
        "experiment = Experiment(ws,'onnxruntime-gpt2')\r\n",
        "\r\n",
        "import uuid\r\n",
        "output_id = uuid.uuid1().hex\r\n",
        "\r\n",
        "output_dir = f'/output/{experiment.name}/{output_id}/'\r\n",
        "print(output_dir)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/output/onnxruntime-gpt2/b579802c1b1111ecbe6b000d3af6b150/\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632252341405
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "source": [
        "# Define the script parameters.\r\n",
        "# To run training PyTorch instead of ORT, remove the --ort_trainer flag.\r\n",
        "# To run evaluation using PyTorch instead of ORT, use the --do_eval_in_torch flag.\r\n",
        "script_params = [\r\n",
        "    '--model_type', 'gpt2-medium', \r\n",
        "    '--model_name_or_path', 'gpt2-medium', \r\n",
        "    '--tokenizer_name' , 'gpt2-medium', \r\n",
        "    '--config_name' , 'gpt2-medium', \r\n",
        "    '--do_eval' , '', \r\n",
        "    '--do_train', '', \r\n",
        "    '--path', '/home/azureuser/cloudfiles/data/dataset/train_data_txt/',\r\n",
        "    '--train_file' ,'train.txt',\r\n",
        "    '--validation_file' , 'valid.txt',\r\n",
        "    '--output_dir' , output_dir, \r\n",
        "    '--per_gpu_train_batch_size' , '4', \r\n",
        "    '--per_gpu_eval_batch_size' , '4', \r\n",
        "    '--gradient_accumulation_steps' , '4',\r\n",
        "    '--block_size' , '1024', \r\n",
        "    '--weight_decay' , '0.01', \r\n",
        "    '--overwrite_output_dir' , '', \r\n",
        "    '--num_train_epocs' , '5',\r\n",
        "    '--ort_trainer' , ''\r\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632268409866
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "source": [
        "import os\r\n",
        "# List the files in the mounted path\r\n",
        "print(os.listdir(\"/home/azureuser/cloudfiles/data/dataset/train_data_txt/\"))\r\n",
        "ds"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train.txt', 'valid.txt']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"name\": \"gpt_wikitext\",\n",
              "  \"container_name\": \"wikitext\",\n",
              "  \"account_name\": \"demo1879244313\",\n",
              "  \"protocol\": \"https\",\n",
              "  \"endpoint\": \"core.windows.net\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632268411757
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "source": [
        "os.path.abspath('/home/azureuser/cloudfiles/data/dataset/train_data_txt/')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/azureuser/cloudfiles/data/dataset/train_data_txt'"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632267048950
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core import ScriptRunConfig\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "docker_config = DockerConfiguration(use_docker=True)\r\n",
        "## env created based on my docker image in aml\r\n",
        "onnxruntime_gpu_env = Environment.get(workspace=ws, name=\"onnxruntime-gpt\")\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632268415876
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "source": [
        "script_run_config = ScriptRunConfig(\r\n",
        "                      source_directory=project_folder,\r\n",
        "                      script='run_language_modeling.py',\r\n",
        "                      arguments = script_params,\r\n",
        "                      #compute\r\n",
        "                      compute_target=gpu_compute_target,\r\n",
        "                      # custom docker image\r\n",
        "                      environment=onnxruntime_gpu_env,\r\n",
        "                      #mpi\r\n",
        "                      distributed_job_config=mpi_distr_config,\r\n",
        "                      docker_runtime_config=docker_config\r\n",
        "                      )"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632268746787
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run AzureML experiment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "source": [
        "experiment.submit(script_run_config)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>onnxruntime-gpt2</td><td>onnxruntime-gpt2_1632268750_1b1bca3e</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/onnxruntime-gpt2_1632268750_1b1bca3e?wsid=/subscriptions/47c81f7b-f720-4f17-9116-69d540091679/resourcegroups/demo/workspaces/demo&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: onnxruntime-gpt2,\n",
              "Id: onnxruntime-gpt2_1632268750_1b1bca3e,\n",
              "Type: azureml.scriptrun,\n",
              "Status: Preparing)"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1632268758734
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pytorch",
      "language": "python",
      "display_name": "Python 3.8 - PyTorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_pytorch"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}